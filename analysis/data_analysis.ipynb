{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.9 64-bit ('venv')",
   "display_name": "Python 3.6.9 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "3c30338ecb16d703437b097d5386462234541e53235eb04d52181597dd5d8e78"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import datas"
   ]
  },
  {
   "source": [
    "## SemEval analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/semeval2016_train.txt'\n",
    "data = []\n",
    "with open(file_path, 'r', encoding='windows-1252') as f:\n",
    "    for row in f.readlines()[1:]:\n",
    "        _, target, claim, stance = row.split('\\t')\n",
    "        data.append([target.strip(), claim.strip(), stance.strip()])\n",
    "\n",
    "# convert to dataframe\n",
    "data_df = pd.DataFrame({'target':[], 'claim':[], 'stance':[]})\n",
    "data_df['target'] = [row[0] for row in data]\n",
    "data_df['claim'] = [row[1] for row in data]\n",
    "data_df['stance'] = [row[2] for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3502"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "claim = data_df['claim'].tolist()\n",
    "claim = [claim.replace('#SemST', '') for claim in claim]\n",
    "\n",
    "tag_count = [claim.count('#') for claim in claim]\n",
    "sum(tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1707"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "tag_count = [claim.count('@') for claim in claim]\n",
    "sum(tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "16.29673063255153"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "len_claim = [len(claim.split()) for claim in claim]\n",
    "sum(len_claim)/len(len_claim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.3212508884150675"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "import re\n",
    "pattern = r'[0-9]+\\S[0-9]*|[0-9]+'\n",
    "patten_claim = [re.findall(pattern, claim) for claim in claim]\n",
    "len_pattern = [len(pattern) for pattern in patten_claim]\n",
    "sum(len_pattern)/len(len_pattern)"
   ]
  },
  {
   "source": [
    "## FNC-1 analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "headline_path = 'data/fnc-1/train_stances.csv'\n",
    "body_path = 'data/fnc-1/train_bodies.csv'\n",
    "\n",
    "headline_df = pd.read_csv(headline_path)\n",
    "body_df = pd.read_csv(body_path)\n",
    "\n",
    "df = pd.DataFrame({'target': [], 'claim': [], 'stance': []})\n",
    "\n",
    "# for index, row in headline_df.iterrows():\n",
    "#     body = body_df.loc[body_df['Body ID'] == row['Body ID'], 'articleBody'].tolist()[0]\n",
    "#     df.loc[index] = [row['Headline'], body, row['Stance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/fnc_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "11.12647082366125"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "len_target = [len(target.split()) for target in df['target'].tolist()]\n",
    "sum(len_target)/len(len_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "368.9922109047334"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "len_claim = [len(claim.split()) for claim in set(df['claim'].tolist())]\n",
    "sum(len_claim)/len(len_claim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                            Headline  Body ID     Stance\n1  Hundreds of Palestinians flee floods in Gaza a...      158      agree\n2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated\n3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Headline</th>\n      <th>Body ID</th>\n      <th>Stance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n      <td>158</td>\n      <td>agree</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n      <td>137</td>\n      <td>unrelated</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n      <td>1034</td>\n      <td>unrelated</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "headline_df.iloc[[1, 2, 3]]"
   ]
  },
  {
   "source": [
    "## MNLI analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "loading MultiNLI testing data: 100%|██████████| 10000/10000 [00:00<00:00, 338621.71it/s]\n"
     ]
    }
   ],
   "source": [
    "df = datas.load_dataset_mnli('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "labels = df['label'].tolist()\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "19.81103228402198"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "len_premise = [len(premise.split()) for premise in df['premise'].tolist()]\n",
    "sum(len_premise)/len(len_premise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "9.972062785521846"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "len_hypothesis = [len(hypothesis.split()) for hypothesis in df['hypothesis'].tolist()]\n",
    "sum(len_hypothesis)/len(len_hypothesis)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "130900"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "df['label'].tolist().count('neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}