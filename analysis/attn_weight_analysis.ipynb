{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "data_path = '../data/attn_weight'\n",
    "single_file = f'{data_path}/v1.0_single_test_weight.csv'\n",
    "multi_file = f'{data_path}/v1.1_test_weight.csv'\n",
    "\n",
    "# read csv\n",
    "single_df = pd.read_csv(single_file)\n",
    "multi_df = pd.read_csv(multi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type\n",
    "columns = ['claim_tokenize', 'target_encode', 'claim_encode', 'claim_decode',\n",
    "           'claim_lexicon', 'task_weight', 'shared_weight']\n",
    "for column in columns:\n",
    "    try:\n",
    "        single_df[column] = (\n",
    "            single_df[column].apply(lambda data: eval(data)))\n",
    "    except:\n",
    "        pass\n",
    "    multi_df[column] = (\n",
    "        multi_df[column].apply(lambda data: eval(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define compare function\n",
    "def compare_result(single_df, multi_df, \n",
    "                   single_correct=True, multi_correct=True):\n",
    "    # get boolean index\n",
    "    if single_correct:\n",
    "        single_boolean = single_df['label_encode'] == single_df['label_pred']\n",
    "    else:\n",
    "        single_boolean = single_df['label_encode'] != single_df['label_pred']\n",
    "\n",
    "    if multi_correct:\n",
    "        multi_boolean = multi_df['label_encode'] == multi_df['label_pred']\n",
    "    else:\n",
    "        multi_boolean = multi_df['label_encode'] != multi_df['label_pred']\n",
    "\n",
    "    # get dataframe index\n",
    "    single_index = single_df[single_boolean].index\n",
    "    multi_index = multi_df[multi_boolean].index\n",
    "\n",
    "    # get intersection index\n",
    "    intersection_index = single_index.intersection(multi_index)\n",
    "\n",
    "    return intersection_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT_index\tTF_index\tFT_index\tFF_index\n",
      "518\t\t162\t\t287\t\t282\n"
     ]
    }
   ],
   "source": [
    "# get compare index\n",
    "TT_index = compare_result(single_df, multi_df, True, True)  # single correct, multi correct\n",
    "TF_index = compare_result(single_df, multi_df, True, False)  # single correct, multi incorrect\n",
    "FT_index = compare_result(single_df, multi_df, False, True)  # single incorrect, multi correct\n",
    "FF_index = compare_result(single_df, multi_df, False, False)  # single incorrect, multi incorrect\n",
    "\n",
    "assert len(single_df) == (\n",
    "    len(TT_index) + len(TF_index) + len(FT_index) + len(FF_index)\n",
    ")\n",
    "\n",
    "print('TT_index', 'TF_index', 'FT_index', 'FF_index', sep='\\t')\n",
    "print(len(TT_index), len(TF_index),\n",
    "      len(FT_index), len(FF_index), sep='\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sample function\n",
    "def sample_data(single_df, multi_df, all_index, target=None):\n",
    "    while True:\n",
    "        # get sample data index\n",
    "        if target is None:\n",
    "            index = random.choice(all_index.tolist())\n",
    "        else:\n",
    "            index = single_df.iloc[all_index][single_df['target'] == target].index\n",
    "            index = random.choice(index.tolist())\n",
    "\n",
    "        # get sample data\n",
    "        single_data, multi_data = (\n",
    "            single_df.iloc[index], multi_df.iloc[index])\n",
    "\n",
    "        # get the column we need\n",
    "        single_data = single_data[['ID', 'target', 'claim', 'claim_decode',\n",
    "                                   'task_weight', 'label_encode', 'label_pred']]\n",
    "        multi_data = multi_data[['claim_decode', 'task_weight',\n",
    "                                 'shared_weight', 'label_pred']]\n",
    "        \n",
    "        # check single weight\n",
    "        seq_len = len(single_data['claim_decode'])\n",
    "        all_weights = single_data['task_weight'][1:seq_len-1]\n",
    "        weight = max(all_weights)\n",
    "        \n",
    "        if weight > 0.1:\n",
    "            break\n",
    "    \n",
    "    # print single result\n",
    "    print(f'Target: {single_data[\"target\"]}')\n",
    "    print(f'ID: {single_data[\"ID\"]}, Claim:  {single_data[\"claim\"]}\\n')\n",
    "\n",
    "    print(f'Single model - label: {single_data[\"label_encode\"]}, '\n",
    "          f'predict: {single_data[\"label_pred\"]}\\n')\n",
    "    print(\"{0:15} {1}\".format('token', 'task_weight'))\n",
    "    for token, weight in zip(single_data['claim_decode'],\n",
    "                             single_data['task_weight']):\n",
    "        token = '[unk]' if token == 'chasingice' else token\n",
    "        print(\"{0:15} {1:.10f}\".format(token, weight))\n",
    "\n",
    "    # print multi result\n",
    "    print(f'\\nTarget: {single_data[\"target\"]}')\n",
    "    print(f'ID: {single_data[\"ID\"]}, Claim:  {single_data[\"claim\"]}\\n')\n",
    "\n",
    "    print(f'Multi model - label: {single_data[\"label_encode\"]}, '\n",
    "          f'predict: {multi_data[\"label_pred\"]}\\n')\n",
    "    print(\"{0:15} {1:12} {2}\".format('token', 'task_weight', 'shared_weight'))\n",
    "    for token, task_weight, shared_weight in zip(multi_data['claim_decode'],\n",
    "                                                 multi_data['task_weight'],\n",
    "                                                 multi_data['shared_weight']):\n",
    "        print(\"{0:15} {1:.10f} {2:.10f}\".format(token, task_weight, shared_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify all the targets\n",
    "targets = ['Atheism', 'Climate Change is a Real Concern',\n",
    "           'Feminist Movement', 'Hillary Clinton',\n",
    "           'Legalization of Abortion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: Feminist Movement\n",
      "ID: 10582, Claim:  I hate it when ignorant losers say \"another feminist cured.\" I don't need to be cured for wanting to be treated like a person. #SemST\n",
      "\n",
      "Single model - label: 0, predict: 0\n",
      "\n",
      "token           task_weight\n",
      "[bos]           0.0751995221\n",
      "i               0.3992257118\n",
      "hate            0.2179879248\n",
      "it              0.0693770871\n",
      "when            0.0318396874\n",
      "ignorant        0.0164023079\n",
      "losers          0.0087089632\n",
      "say             0.0267525520\n",
      "[unk]           0.0053545325\n",
      "feminist        0.0149391228\n",
      "[unk]           0.0022944261\n",
      "i               0.0050446549\n",
      "[unk]           0.0029496253\n",
      "need            0.0265847184\n",
      "to              0.0051019341\n",
      "be              0.0011549945\n",
      "[unk]           0.0002179704\n",
      "for             0.0008856706\n",
      "wanting         0.0002687991\n",
      "to              0.0001517127\n",
      "be              0.0000688030\n",
      "treated         0.0000219532\n",
      "like            0.0000079527\n",
      "a               0.0000417886\n",
      "[unk]           0.0000167918\n",
      "[unk]           0.0000443778\n",
      "[eos]           0.0575636216\n",
      "\n",
      "Target: Feminist Movement\n",
      "ID: 10582, Claim:  I hate it when ignorant losers say \"another feminist cured.\" I don't need to be cured for wanting to be treated like a person. #SemST\n",
      "\n",
      "Multi model - label: 0, predict: 1\n",
      "\n",
      "token           task_weight  shared_weight\n",
      "[bos]           0.0001189628 0.0000000239\n",
      "hate            0.0118366107 0.0622521266\n",
      "ignorant        0.0015663826 0.0138768489\n",
      "losers          0.0008655179 0.0002604388\n",
      "say             0.0002239975 0.0000415654\n",
      "another         0.0000204281 0.0000006930\n",
      "feminist        0.0000010867 0.0000117015\n",
      "cured           0.0000003242 0.0001453800\n",
      "[unk]           0.0000117185 0.0390905328\n",
      "need            0.0000013441 0.0003510742\n",
      "cured           0.0000000945 0.1490383893\n",
      "wanting         0.0000019838 0.0679820105\n",
      "treated         0.0000050151 0.0002343473\n",
      "like            0.0000051382 0.0012422546\n",
      "person          0.0001076308 0.0001620931\n",
      "[unk]           0.9852204323 0.0193151254\n",
      "[pad]           0.0000110065 0.1478850394\n",
      "[pad]           0.0000019497 0.2747407854\n",
      "[pad]           0.0000004457 0.2228835225\n",
      "[eos]           0.0000000045 0.0004860932\n"
     ]
    }
   ],
   "source": [
    "# sample single correct, multi correct data\n",
    "sample_data(single_df, multi_df, TF_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
