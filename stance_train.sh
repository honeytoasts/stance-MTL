python stance_train.py \
    --experiment_no 2 \
    --tokenizer WordPunctTokenizer \
    --filter none \
    --min_count 1 \
    --max_seq_len 20 \
    --padding False \
    --stance_dataset semeval2016 \
    --nli_dataset mnli \
    --nli_dataset_size 1.0 \
    --embedding glove/glove.twitter.27B.200d.txt \
    --lexicon emolex_sentiment \
    --stance_output_dim 3 \
    --nli_output_dim 3 \
    --embedding_dim 200 \
    --task_hidden_dim 100 \
    --shared_hidden_dim 100 \
    --stance_linear_dim 100 \
    --nli_linear_dim 50 \
    --num_rnn_layers 2 \
    --num_linear_layers 2 \
    --attention dot \
    --rnn_dropout 0.2 \
    --linear_dropout 0.5 \
    --learning_rate 1e-4 \
    --weight_decay 0 \
    --clip_grad_value 0 \
    --lr_decay_step 10 \
    --lr_decay 1 \
    --nli_loss_weight 1.0 \
    --lexicon_loss_weight 0 \
    --random_seed 73 \
    --kfold 5 \
    --test_size 0.15 \
    --epoch 70 \
    --batch_size 16